%% This LaTeX-file was created by Marco Kienzle (Marco.Kienzle@gmail.com)
%% 
%% Do not edit this file unless you know what you are doing.

\documentclass{article}

% Language & comments
%\usepackage[french, english, swedish]{babel}	

\usepackage{amsmath}
\usepackage{amssymb}        % pi, infinity, natural/real symbol...
%\usepackage{hyperref} 		% interactive pdfs 
%\usepackage{apacite}        % APA
\usepackage[comma]{natbib}	  % citation
\usepackage{pdfpages}


%\usepackage[dvips]{color}

%\usepackage{natbib}
\usepackage{authblk}
\usepackage{setspace}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{etoolbox}
\makeatletter
\patchcmd{\Ginclude@eps}{"#1"}{#1}{}{}
\makeatother
%\usepackage{psfig}
\usepackage{verbatim}
\usepackage{rotating}
\usepackage{multirow}
\usepackage{longtable}
\usepackage{booktabs}
\usepackage{subfigure}
\usepackage{lineno}
\usepackage{pbox} % multiple line in table cells
\usepackage{url}

\usepackage{fancyhdr}
\pagestyle{fancyplain} %Note the \fancyplain command !!!
\fancyheadoffset{1 cm} 
%\renewcommand{\chaptermark}[1]{\markboth{#1}{}}
%\renewcommand{\sectionmark}[1]{\markright{#1}{}}
\lhead[\fancyplain{E}{EE}] {\fancyplain{}{}}
\chead[\fancyhead{}{}]{\fancyplain{}{Draft}}
\cfoot [ ] {\copyright \hspace{0.1cm} State of Queensland through the Department of Agriculture and Fisheries (2017) \begin{center} \thepage \end{center}}

\setlength{\oddsidemargin}{0.5cm}
\setlength{\evensidemargin}{0.5cm}
\setlength{\textwidth}{17cm}
\renewcommand{\baselinestretch}{2.0} % set space between lines to 1.5
\DeclareMathOperator*{\argmax}{arg\,max}

\begin{document}
\linenumbers

%\title{Optimal harvest strategy for fishing tiger prawns in Moreton Bay according to a Markov Decision Process}
%\title{Optimal Economic Harvest Strategy from a Markov Decision Process applied to a delay-difference model: insights from the tiger prawn fishery in Moreton Bay (Australia) case study}
\title{Optimal Harvest Strategies according to a Markov Decision Process applied to a delay-difference model: insights from the tiger prawn fishery in Moreton Bay (Australia)}
\author[1,2,5]{Marco Kienzle}
\author[3,4]{Martin P\'{e}ron}
\author[3]{Sam Nicol}
\author[3]{Yann Dujardin}
\author[3]{Iadine Chad\`{e}s}

\affil[1]{Queensland Department of Agriculture and Fisheries, Dutton Park QLD 4102, Australia}
\affil[2]{Centre for Applications in Natural Resource Mathematics, School of Mathematics and Physics, University of Queensland, Australia}
\affil[3]{CSIRO, GPO Box 2583, Brisbane QLD 4001, Australia}
\affil[4]{School of Mathematical Sciences, Queensland University of Technology, Brisbane QLD 4000, Australia}
%\affil[5]{Somewhere in Europe}
\affil[5]{Corresponding author: Marco.Kienzle@daf.qld.gov.au}

\maketitle

%\tableofcontents
\clearpage
\newpage

\abstract{\input{abstract.tex}}
\section*{keywords}
Markov Decision Process, bio-economic model, delay-difference model, brown tiger prawn

\clearpage
\newpage

\section{Introduction} \input{introduction.tex}

\section{Materials and methods} 
\input{MDPs.tex}

\subsection{From calibrated stock assessment model to transition matrix}

%\paragraph{Parameterizing the MDP using the stock assessment model} \mbox{} \\

\input{TheDelayDifferenceModel.tex}

\section{Results} \input{Results.tex}

\section{Discussion} \input{discussions.tex}


\clearpage
\newpage

\section*{Acknowledgements} Catch and effort data were provided by the State of Queensland (Australia) through the Department of Agriculture and Fisheries. We would like to thanks Dr. D. Mayer, Dr. A.J. Courtney and internal reviewers for reading and correcting an early version of this manuscript. We valued the guidance Prof. J. Filar and Dr. S. Pascoe during the development of this MDP application. We are grateful to Dr. David Sterling and Mr. Michael Wood from Moreton Bay Seafood Industry Association for contributing their insights into this fishery as professional fishers involved in fishing this stock.
\bibliography{a-JLong,Biblio,phd}
\bibliographystyle{plainnat}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newpage
\section*{Figures}

%%%%% Map of the distribution of tiger prawn around Australia
   \begin{figure}[h!]
     \begin{center}
 \includegraphics[scale=0.5, angle = 0]{MoretonBaytrawlfisheryandtigerprawndistribution3.ps}
       \caption{Top map: the spatial distribution of the brown tiger prawn ({\it Penaeus esculentus}) in Australia (from \cite{Grey83r}) with the location of Moreton Bay indicated by a black square. Bottom map: the location of trawling ground in Moreton Bay (greyed area) covering an ar
ea of about 800 km$^{2}$.}
       \label{fig:Map}
     \end{center}
  \end{figure}

%%%%%% Diagram of a MDP
\begin{figure}[!ht]
\begin{center}
%\includegraphics[width=0.2\textwidth,natwidth=300,natheight=100]{mdp.PNG}
\includegraphics{mdp.eps}
\end{center}
\caption[Decision diagram of a Markov Decision Process]{Decision diagram of a Markov Decision Process. Full arrows show relations of dependence, e.g. the value of $s_{t+1}$ (or $s'$) depends on $s_t$ (or $s$) through the probability $p$. Dashed arrows illustrate what factors the agent bases their decision upon; here, the best action is based on the current state only (Markov property).}
\label{fig:mdp}
\end{figure}

%%%%%% Beverton and Holt stock recruitment relationship
\begin{figure}[!ht]
  \begin{center}
        \includegraphics[scale=0.5,angle=-90]{BevertonAndHoltSRR-NaturalScale-WithCategories.eps}
    \caption{Beverton and Holt stock recruitment relationship fitted to the data. The recruitment categories used in the MDP are delimited with horizontal grey lines.}
    \label{fig:BevertonAndHoltSRR-NaturalScale-WithCategories}
  \end{center}
\end{figure}

%%%%%% Optimal catch using constant effort through time
\begin{figure}[!ht]
  \begin{center}
        \includegraphics[scale=0.6,angle=-90]{ProjectedCatchvsEffort.eps}
    \caption{Estimation of optimal yield, Maximum Average Yield (MAY), using constant effort of 20.500 boat-days per year through time.}
    \label{fig:ProjectedCatchvsEffort}
  \end{center}
\end{figure}


%%%%%% Pattern of fishing effort targeted at tiger prawn
\begin{figure}[!ht]
  \begin{center}
        \includegraphics[scale=0.5,angle=-90]{EffortPattern.eps}
    \caption{Average weekly pattern of fishing effort targeted at tiger prawn observed between 2006 and 2010.}
    \label{fig:EffortPattern}
  \end{center}
\end{figure}


%% Transition matrices
\begin{figure}[!ht]
  \begin{center}
        \includegraphics[scale=0.6,angle=-90]{BubblePlotOfTransitionMatrix.eps}
    \caption{Representation of the transition matrices giving the probability of fishery to move from a given level of recruitment (low, medium or high) in year $t$ (y-axis) and to any recruitment category in year $t+1$ (x-axis) for a range of fishing pressure: no fishing (top left panel); 19,000--20,000 boat-days (top right) and 29,000--30,000 boat-days (bottom left).}
    \label{fig:BubblePlotOfTransitionMatrix}
  \end{center}
\end{figure}

%% MDP results sensitivity to discount factor
\begin{figure}[!ht]
  \begin{center}
        \includegraphics[scale=1,angle=-90]{SensitivityToDiscountFactor.eps}
    \caption{Sensitivity analysis of the MDP results to the value of the discount factor ($\gamma$) for prawn price fixed at \$12/kg. Each panel shows the optimal fishing effort (y-axis) to maximize profit according to recruitment level (x-axis) for a discount factor value at various costs of fishing ranging from \$0 to \$500 per boat-day (see legend). The horizontal dashed line indicates effort at MAY (${\rm E_{MAY}=19,500 boat-days}$). More details are given in supplemental material, Fig.~\ref{fig:SensitivityToDiscountFactorLONGVERSION}.}
    \label{fig:SensitivityToDiscountFactor}
  \end{center}
\end{figure}

    
%% Optimal strategy according to the MDP 
%\begin{figure}[!ht]
%  \begin{center}
%        \includegraphics[scale=0.6,angle=-90]{MDPonProfit_finalVersion.eps}
%     \caption{Optimal fishing effort (y-axis) in response to the state of the fishery (x-axis) given a prawn price of 12\$/kg and fishing costs varying from 0 to 500\$ per boat-day. The horizontal dotted line indicates the effort required to achieve Maximum Average Yield (${\rm E_{MAY}}$)).}
%    \label{fig:MDPonProfit}
%  \end{center}
%\end{figure}

%% Compare MDP results with observations
\begin{figure}[!ht]
   \subfigure[]{ % FROM THE SUBFIGURE PACKAGE
    \label{fig:PlotEffortAgainstRecruitment}
    \begin{minipage}[b]{0.5\textwidth}
          \includegraphics[scale=0.45, angle = -90]{PlotEffortAgainstRecruitment.eps}
   \end{minipage}
}
 \subfigure[]{ % FROM THE SUBFIGURE PACKAGE
    \label{fig:MDPonProfit-OverlayedWithObs}
    \begin{minipage}[b]{0.5\textwidth}
          \includegraphics[scale=0.45, angle = -90]{MDPonProfit-OverlayedWithObs.eps}
   \end{minipage}
}
%% Plot MDP results on a yield (y-axis) versus recruitment (x-axis) plot as presented by Hilborn & Walters (1992) p.455
   \subfigure[]{ % FROM THE SUBFIGURE PACKAGE
    \label{fig:MDPonProfit-RecCatAgainstCatch-OverlayedWithObs}
    \begin{minipage}[b]{0.5\textwidth}
          \includegraphics[scale=0.45, angle = -90]{MDPonProfit-PlottedAgainstCatchOverlayedWithObs.eps}
          \label{MDPonProfit-RecCatAgainstCatch-OverlayedWithObs}
          \end{minipage}
          }
     \caption{Comparison of MDP optimal policies to observations: (a) observed relation between recruitment (x-axis) and effort (y-axis) with regression line overlayed (b) optimal strategies for $\gamma=0.8$ overlayed with observed effort (grey circles) and recruitment binned into the discrete categories used for the MDP (c) Average yield from each optimal strategy overlayed with observed yield as a function of recruitment category in each year. The horizontal dotted line indicates the Maximum Average Yield (MAY) or $\rm{E_{MAY}}$.}
    \label{}
  \end{figure}

%% Effect of varying prawn prices on MDP outcomes
\begin{figure}[!ht]
  \begin{center}
    \includegraphics[scale=1, angle=-90]{SensitivityToPrawnPrice.eps}
    \caption{Effect of varying prawn prices on optimal fishing policies. Each panel shows the optimal fishing effort (y-axis) to maximize profit according to recruitment level (x-axis) for various prawn prices ($P$) varying from \$12 to \$100 per kg for various costs of fishing ranging from 0 to \$500 per boat-day (see legend).}
    \label{fig:SensitivityToPrawnPrice}
  \end{center}
\end{figure}


%% Simulate states, actions and rewards of various strategies
\begin{figure}[!ht]
   \subfigure[]{ % FROM THE SUBFIGURE PACKAGE
    \label{fig:CompareVariousStrategies-1Simulation-TimeseriesOfStates}
    \begin{minipage}[b]{0.5\textwidth}
          \includegraphics[scale=0.25, angle = -90]{CompareVariousStrategies-1Simulation-TimeseriesStatesAndActionsOptimalAndRandomEffort.eps}
   \end{minipage}
}
 \subfigure[]{ % FROM THE SUBFIGURE PACKAGE
    \label{fig:CompareVariousStrategies-1Simulation-TimeseriesOfActions}
    \begin{minipage}[b]{0.5\textwidth}
          \includegraphics[scale=0.25, angle = -90]{CompareVariousStrategies-1Simulation-TimeseriesStatesAndActionsCteEffortLowAndMay.eps}
   \end{minipage}
}
   \subfigure[]{ % FROM THE SUBFIGURE PACKAGE
    \label{fig:CompareVariousStrategies-1Simulation-CumulativeReward}
    \begin{minipage}[b]{0.5\textwidth}
          \includegraphics[scale=0.25, angle = -90]{CompareVariousStrategies-1Simulation-AverageYearlyReward.eps}
          \end{minipage}
          }
    \subfigure[]{ % FROM THE SUBFIGURE PACKAGE
    \label{fig:CompareVariousStrategies-repeat1000times}
    \begin{minipage}[b]{0.5\textwidth}
          \includegraphics[scale=0.25, angle = -90]{CompareVariousStrategies-repeat1000times.eps}
          \end{minipage}
          }
         
     \caption{Simulations comparing the performance of 4 harvest strategies: (1) the optimal harvest strategy; (2) a random fishing strategy; (3) a constant low effort fishing strategy  and (4) a constant effort strategy at ${\rm{E_{MAY}}}$. These simulations were performed for a cost of fishing of \$200 per boat-day and a price of prawns of \$12 per kg. Panel (a) shows time series from a single simulation of tiger prawn recruitment (states) and effort category (actions) according to the optimal and the random effort strategy over a 50 years period. Panel (b) shows the same variables for constant low and constant $E_{\rm MAY}$ strategy. Panel (c) shows the average yearly profit made by each strategy. Panel (d) summarizes the average yearly profit according to each strategy for 1000 simulations over a 50 year period.}
    \label{fig:simulations}
  \end{figure}



%% 
%\begin{figure}[!ht]
%  \begin{center}
%    \includegraphics[scale=0.5,angle=-90]{EffortSurface.eps}
%    \caption{Isoclines of average action category as a function of prawn price per kilo (y-axis) and cost of 1 fishing boat-day (x-axis).}
%    \label{fig:EffortSurface}
%  \end{center}
%\end{figure}


%\clearpage
%\newpage
%\section*{Tables}
%\input{AverageValueAsFctPricesAndCosts.tex}

%%%%%%%%%% Merge with supplemental materials %%%%%%%%%%
\clearpage
\begin{center}
\textbf{\large Supplemental Materials: Optimal Harvest Strategies according to a Markov Decision Process applied to a delay-difference model: insights from the tiger prawn fishery in Moreton Bay (Australia)}
\end{center}

%%%%%%%%%% Merge with supplemental materials %%%%%%%%%%
%%%%%%%%%% Prefix a "S" to all equations, figures, tables and reset the counter %%%%%%%%%%
\setcounter{section}{0}
\setcounter{equation}{0}
\setcounter{figure}{0}
\setcounter{table}{0}
\setcounter{page}{1}
\makeatletter
\renewcommand{\thesection}{S\arabic{section}}
\renewcommand{\theequation}{S\arabic{equation}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\bibnumfmt}[1]{[S#1]}
\renewcommand{\citenumfont}[1]{S#1}
%%%%%%%%%% Prefix a "S" to all equations, figures, tables and reset the counter %%%%%%%%%%

%% Policy iteration algorithm
\section{Policy iteration algorithm}
\label{SuppSection-PolicyIterationAlgo}

Policy iteration unfolds as follows: starting from any initial policy $\pi_0$, the best current policy $\pi$ is evaluated (step 1) and improved (step 2) repeatedly until it is optimal ($\pi^*$).  \\

1) The evaluation consists of calculating a value $V_\pi(s)$ for each state $s \in S$. This value corresponds to the sum of future rewards one can expect, starting from the state $s$ when implementing the policy $\pi$. The value function captures the desirability of the different states, and will help select the optimal actions. Formally,

\begin{equation}
V_\pi(s) = \mathbb{E}[\sum\limits_{t=0}^\infty \gamma^t r(s_t,\pi(s_t))|s_0=s]
\end{equation}

The following recursive formula holds: 

\begin{equation}
V_\pi(s) = r(s,\pi(s)) + \gamma \sum_{s' \in S} P(s'|s,\pi(s)) V_\pi(s')
\end{equation}

This can be calculated recursively (applying this formula until convergence of $V_\pi$) or by solving the following linear system, since the value function can be rewritten: 

\begin{equation}
V_\pi = r_\pi + \gamma P_\pi V_\pi
\end{equation}
with $r_\pi$ and $P_\pi$ the reward and transition matrix associated with the policy $\pi$. Denoting by $I$ the identity matrix, this implies

\begin{equation}
V_\pi = (I-\gamma P_\pi)^{-1}r_\pi  \label{eq:evaluation}
\end{equation}

Note that $I-\gamma P_\pi$ is always invertible when $\gamma<1$ because $P_\pi$ is a transition matrix. \\

2) Once the value $V_\pi$ has been evaluated, we can improve the policy $\pi$ by selecting the best actions (Bellman's equation \citep{bellman_dynamic_1957, puterman_markov_1994}): 

\begin{equation} \label{eq:improvement}
\pi(s) = \argmax_{a \in A} [r(s,a)+ \gamma \sum_{s' \in S} P(s'|s,a)V_\pi(s')]
\end{equation}

Equations \ref{eq:evaluation} and \ref{eq:improvement} are computed several times until the policy $\pi$ converges to the optimal policy $\pi^*$ using the MDPtoolbox package in R \citep{MDPtoolbox}. The sequence of $V_\pi$ is monotonic, so convergence is guaranteed \citep{sigaud_markov_2010}. The outputs of policy iteration are the optimal policy $\pi^*$ and the optimal value $V_\pi^*$. \\

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\clearpage
\newpage
\section*{Figures}


%% MDP results sensitivity to discount factor
\begin{figure}[!ht]
  \begin{center}
        \includegraphics[scale=0.85,angle=-90]{SensitivityToDiscountFactorLONGVERSION.eps}
    \caption{Sensitivity analysis of the MDP results to the value of the discount factor ($\gamma$). Each panel shows the optimal fishing effort (y-axis) to maximize profit according to recruitment level (x-axis) for a discount factor value at various costs of fishing ranging from \$0 to \$500 per boat-day (see legend). The horizontal dashed line indicates effort at MAY (${\rm E_{MAY}}$).}
    \label{fig:SensitivityToDiscountFactorLONGVERSION}
  \end{center}
\end{figure}

\end{document}









